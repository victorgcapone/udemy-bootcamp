{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Red</td>\n",
       "      <td>196130.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13707.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>223875.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Black</td>\n",
       "      <td>11049.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>209466.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>72575.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41294.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "521  Nissan    Red       196130.0    3.0  13707.0\n",
       "737  Toyota   Blue       223875.0    4.0  12650.0\n",
       "740     BMW  Black        11049.0    3.0  19500.0\n",
       "660     BMW   Blue       209466.0    5.0      NaN\n",
       "411     BMW   Blue        72575.0    5.0  41294.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data = pd.read_csv('resources/car-sales-extended-missing-data.csv')\n",
    "car_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use sklearn Pipelines to pre-process our data\n",
    "# This includes making everything a number, dealing with missing values\n",
    "# and One Hot Encoding our categorical features\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "# First, we drop rows with missing labels (Price Column)\n",
    "car_data.dropna(subset=[\"Price\"], inplace=True)\n",
    "\n",
    "# Define different features and transformer pipelines\n",
    "categorical_features = [\"Make\", \"Colour\"]\n",
    "# Here we create a pipeline which has a list of steps to take\n",
    "# on our data, each step in the list is a tuple (name, action)\n",
    "categorical_transformer = Pipeline(\n",
    "    steps = [\n",
    "        (\"inputer\", SimpleImputer(strategy='constant', fill_value='missing')), # Fill NA values with \"missing\"\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown='ignore')) # One Hot Encode all features\n",
    "    ]\n",
    ")\n",
    "\n",
    "doors_feature = [\"Doors\"]\n",
    "doors_tranformer = Pipeline(\n",
    "    steps = [\n",
    "        (\"inputer\", SimpleImputer(strategy='constant', fill_value=4))\n",
    "    ]\n",
    ")\n",
    "\n",
    "numeric_features = [\"Odometer (KM)\"]\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"inputer\", SimpleImputer(strategy='mean'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a preprocessor that applies all of our transformations to the data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers= [\n",
    "        (\"categorical\", categorical_transformer, categorical_features),\n",
    "        (\"doors\", doors_tranformer, doors_feature),\n",
    "        (\"numeric\", numeric_transformer, numeric_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will combine the preprocessing steps with the model training step by using pipelines again!\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = Pipeline(steps = [\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('training', RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now prepare our data so we can feed it to the pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = car_data.drop(\"Price\", axis=1)\n",
    "y = car_data[\"Price\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2920060423100943"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And finally we can train the model\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   40.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38413246082945096"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cool, but we are not doing any Croos Validation or hyperparameter tunning in this pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Lets creat a grid with the hyperparameter for the ENTIRE pipeline\n",
    "pipeline_grid = {\n",
    "    # This entry correspond to the strategy of our numeric inputer in the preprocessing step \n",
    "    # note: double underscores\n",
    "    \"preprocessing__numeric__inputer__strategy\" : [\"mean\", \"median\"],\n",
    "    # The n_estimators paramenters, note that since we are no navigating in the \n",
    "    # pipeline hierarchy, there is no need for the double underscore\n",
    "    # between n and estimators\n",
    "    \"training__n_estimators\": [100, 200, 500],\n",
    "    \"training__max_depth\": [None, 5],\n",
    "    \"training__max_features\": [\"auto\"],\n",
    "    \"training__min_samples_split\": [2,4]\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(model, pipeline_grid, cv=5, verbose=1)\n",
    "grid_cv.fit(x_train, y_train)\n",
    "grid_cv.score(x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (udemy)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
